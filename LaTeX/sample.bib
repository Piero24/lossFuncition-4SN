%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Andrea Pietrobon at 2023-05-17 02:21:00 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{ZHANG2022106173,
	abstract = {Automatic polyp segmentation can help physicians to effectively locate polyps (a.k.a. region of interests) in clinical practice, in the way of screening colonoscopy images assisted by neural networks (NN). However, two significant bottlenecks hinder its effectiveness, disappointing physicians' expectations. (1) Changeable polyps in different scaling, orientation, and illumination, bring difficulty in accurate segmentation. (2) Current works building on a dominant decoder--encoder network tend to overlook appearance details (e.g., textures) for a tiny polyp, degrading the accuracy to differentiate polyps. For alleviating the bottlenecks, we investigate a hybrid semantic network (HSNet) that adopts both advantages of Transformer and convolutional neural networks (CNN), aiming at improving polyp segmentation. Our HSNet contains a cross-semantic attention module (CSA), a hybrid semantic complementary module (HSC), and a multi-scale prediction module (MSP). Unlike previous works on segmenting polyps, we newly insert the CSA module, which can fill the gap between low-level and high-level features via an interactive mechanism that exchanges two types of semantics from different NN attentions. By a dual-branch structure of Transformer and CNN, we newly design an HSC module, for capturing both long-range dependencies and local details of appearance. Besides, the MSP module can learn weights for fusing stage-level prediction masks of a decoder. Experimentally, we compared our work with 10 state-of-the-art works, including both recent and classical works, showing improved accuracy (via 7 evaluative metrics) over 5 benchmark datasets, e.g., it achieves 0.926/0.877 mDic/mIoU on Kvasir-SEG, 0.948/0.905 mDic/mIoU on ClinicDB, 0.810/0.735 mDic/mIoU on ColonDB, 0.808/0.74 mDic/mIoU on ETIS, and 0.903/0.839 mDic/mIoU on Endoscene. The proposed model is available at (https://github.com/baiboat/HSNet).},
	author = {Wenchao Zhang and Chong Fu and Yu Zheng and Fangyuan Zhang and Yanli Zhao and Chiu-Wing Sham},
	date-added = {2023-05-17 02:18:32 +0200},
	date-modified = {2023-05-17 02:18:32 +0200},
	doi = {https://doi.org/10.1016/j.compbiomed.2022.106173},
	issn = {0010-4825},
	journal = {Computers in Biology and Medicine},
	keywords = {Polyp segmentation, Hybrid semantic, Dual-branch, Long-range dependencies, Local details},
	pages = {106173},
	title = {HSNet: A hybrid semantic network for polyp segmentation},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482522008812},
	volume = {150},
	year = {2022},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0010482522008812},
	bdsk-url-2 = {https://doi.org/10.1016/j.compbiomed.2022.106173}}

@misc{https://doi.org/10.48550/arxiv.2108.01405,
	author = {Valverde, Juan Miguel and Tohka, Jussi},
	copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	date-added = {2023-05-17 02:14:46 +0200},
	date-modified = {2023-05-17 02:14:46 +0200},
	doi = {10.48550/ARXIV.2108.01405},
	keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Region-wise Loss for Biomedical Image Segmentation},
	url = {https://arxiv.org/abs/2108.01405},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2108.01405},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2108.01405}}

@article{Kervadec_2021,
	author = {Hoel Kervadec and Jihene Bouchtiba and Christian Desrosiers and Eric Granger and Jose Dolz and Ismail Ben Ayed},
	date-added = {2023-05-17 02:14:07 +0200},
	date-modified = {2023-05-17 02:14:07 +0200},
	doi = {10.1016/j.media.2020.101851},
	journal = {Medical Image Analysis},
	month = {jan},
	pages = {101851},
	publisher = {Elsevier {BV}},
	title = {Boundary loss for highly unbalanced segmentation},
	url = {https://doi.org/10.1016%2Fj.media.2020.101851},
	volume = {67},
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.1016%2Fj.media.2020.101851},
	bdsk-url-2 = {https://doi.org/10.1016/j.media.2020.101851}}

@misc{https://doi.org/10.48550/arxiv.1904.10030,
	author = {Karimi, Davood and Salcudean, Septimiu E.},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2023-05-17 02:12:39 +0200},
	date-modified = {2023-05-17 02:12:39 +0200},
	doi = {10.48550/ARXIV.1904.10030},
	keywords = {Image and Video Processing (eess.IV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Reducing the Hausdorff Distance in Medical Image Segmentation with Convolutional Neural Networks},
	url = {https://arxiv.org/abs/1904.10030},
	year = {2019},
	bdsk-url-1 = {https://arxiv.org/abs/1904.10030},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1904.10030}}

@article{su13031224,
	abstract = {As an emerging biomedical image processing technology, medical image segmentation has made great contributions to sustainable medical care. Now it has become an important research direction in the field of computer vision. With the rapid development of deep learning, medical image processing based on deep convolutional neural networks has become a research hotspot. This paper focuses on the research of medical image segmentation based on deep learning. First, the basic ideas and characteristics of medical image segmentation based on deep learning are introduced. By explaining its research status and summarizing the three main methods of medical image segmentation and their own limitations, the future development direction is expanded. Based on the discussion of different pathological tissues and organs, the specificity between them and their classic segmentation algorithms are summarized. Despite the great achievements of medical image segmentation in recent years, medical image segmentation based on deep learning has still encountered difficulties in research. For example, the segmentation accuracy is not high, the number of medical images in the data set is small and the resolution is low. The inaccurate segmentation results are unable to meet the actual clinical requirements. Aiming at the above problems, a comprehensive review of current medical image segmentation methods based on deep learning is provided to help researchers solve existing problems.},
	article-number = {1224},
	author = {Liu, Xiangbin and Song, Liping and Liu, Shuai and Zhang, Yudong},
	date-added = {2023-05-17 02:06:17 +0200},
	date-modified = {2023-05-17 02:06:17 +0200},
	doi = {10.3390/su13031224},
	issn = {2071-1050},
	journal = {Sustainability},
	number = {3},
	title = {A Review of Deep-Learning-Based Medical Image Segmentation Methods},
	url = {https://www.mdpi.com/2071-1050/13/3/1224},
	volume = {13},
	year = {2021},
	bdsk-url-1 = {https://www.mdpi.com/2071-1050/13/3/1224},
	bdsk-url-2 = {https://doi.org/10.3390/su13031224}}

@article{Valverde:2020um,
	abstract = {We present a fully convolutional neural network (ConvNet), named RatLesNetv2, for segmenting lesions in rodent magnetic resonance (MR) brain images. RatLesNetv2 architecture resembles an autoencoder and it incorporates residual blocks that facilitate its optimization. RatLesNetv2 is trained end to end on three-dimensional images and it requires no preprocessing. We evaluated RatLesNetv2 on an exceptionally large dataset composed of 916 T2-weighted rat brain MRI scans of 671 rats at nine different lesion stages that were used to study focal cerebral ischemia for drug development. In addition, we compared its performance with three other ConvNets specifically designed for medical image segmentation. RatLesNetv2 obtained similar to higher Dice coefficient values than the other ConvNets and it produced much more realistic and compact segmentations with notably fewer holes and lower Hausdorff distance. The Dice scores of RatLesNetv2 segmentations also exceeded inter-rater agreement of manual segmentations. In conclusion, RatLesNetv2 could be used for automated lesion segmentation, reducing human workload and improving reproducibility. RatLesNetv2 is publicly available at https://github.com/jmlipman/RatLesNetv2.},
	address = {A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio, Finland.; Charles River Discovery Services, Kuopio, Finland.; A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio, Finland.; Centro Fermi-Museo Storico della Fisica e Centro Studi e Ricerche Enrico Fermi, Rome, Italy.; Sapienza Universit{\`a}di Roma, Rome, Italy.; A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio, Finland.; A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio, Finland.; A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, Kuopio, Finland.},
	author = {Valverde, Juan Miguel and Shatillo, Artem and De Feo, Riccardo and Gr{\"o}hn, Olli and Sierra, Alejandra and Tohka, Jussi},
	cois = {As disclosed in the affiliation section, ASh is a full-time payroll employee of the Charles River Discovery Services, Finland---a commercial pre-clinical contract research organization (CRO), which participated in the project and provided raw data as a part of company's R&D initiative. The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.},
	copyright = {Copyright {\copyright}2020 Valverde, Shatillo, De Feo, Gr{\"o}hn, Sierra and Tohka.},
	crdt = {2021/01/08 06:10},
	date = {2020},
	date-added = {2023-05-17 02:06:13 +0200},
	date-modified = {2023-05-17 02:06:13 +0200},
	dep = {20201222},
	doi = {10.3389/fnins.2020.610239},
	edat = {2021/01/09 06:00},
	issn = {1662-4548 (Print); 1662-453X (Electronic); 1662-453X (Linking)},
	jid = {101478481},
	journal = {Front Neurosci},
	jt = {Frontiers in neuroscience},
	keywords = {deep learning; ischemic stroke; lesion segmentation; magnetic resonance imaging; rat brain},
	language = {eng},
	lid = {10.3389/fnins.2020.610239 {$[$}doi{$]$}; 610239},
	lr = {20210111},
	mhda = {2021/01/09 06:01},
	oto = {NOTNLM},
	own = {NLM},
	pages = {610239},
	phst = {2020/09/25 00:00 {$[$}received{$]$}; 2020/11/25 00:00 {$[$}accepted{$]$}; 2021/01/08 06:10 {$[$}entrez{$]$}; 2021/01/09 06:00 {$[$}pubmed{$]$}; 2021/01/09 06:01 {$[$}medline{$]$}},
	pl = {Switzerland},
	pmc = {PMC7783408},
	pmid = {33414703},
	pst = {epublish},
	pt = {Journal Article},
	status = {PubMed-not-MEDLINE},
	title = {RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion Segmentation.},
	volume = {14},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.3389/fnins.2020.610239}}

@comment{BibDesk URL Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>URL</key>
		<string>file:///Users/pietrobon/Downloads/33414703.nbib</string>
		<key>group name</key>
		<string>33414703.nbib</string>
	</dict>
	<dict>
		<key>URL</key>
		<string>file:///Users/pietrobon/Downloads/S0010482522008812.bib</string>
		<key>group name</key>
		<string>S0010482522008812.bib</string>
	</dict>
	<dict>
		<key>URL</key>
		<string>file:///Users/pietrobon/Downloads/sustainability-v13-i03_20230517.bib</string>
		<key>group name</key>
		<string>sustainability-v13-i03_20230517.bib</string>
	</dict>
</array>
</plist>
}}
